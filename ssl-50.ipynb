{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df831601",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-17T18:53:00.765118Z",
     "iopub.status.busy": "2025-04-17T18:53:00.764888Z",
     "iopub.status.idle": "2025-04-17T20:55:48.914316Z",
     "shell.execute_reply": "2025-04-17T20:55:48.913251Z"
    },
    "papermill": {
     "duration": 7368.2968,
     "end_time": "2025-04-17T20:55:49.057920",
     "exception": false,
     "start_time": "2025-04-17T18:53:00.761120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 590 valid image-mask pairs\n",
      "Dataset split: 236 train, 94 val, 142 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 216MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial backbone weights (first layer):\n",
      "conv1.weight: 0.013334773480892181\n",
      "Missing keys: []\n",
      "Unexpected keys: []\n",
      "\n",
      "Loaded MoCo weights (first layer):\n",
      "conv1.weight: 0.036203160881996155\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:05<00:00,  4.20s/it, loss=0.747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7474\n",
      "Val Loss: 0.6953\n",
      "Dice Score: 0.3217\n",
      "Saved best model with Dice score: 0.3217\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.30s/it, loss=0.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6702\n",
      "Val Loss: 0.6291\n",
      "Dice Score: 0.3726\n",
      "Saved best model with Dice score: 0.3726\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6307\n",
      "Val Loss: 0.6220\n",
      "Dice Score: 0.3865\n",
      "Saved best model with Dice score: 0.3865\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5889\n",
      "Val Loss: 0.5651\n",
      "Dice Score: 0.4349\n",
      "Saved best model with Dice score: 0.4349\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5786\n",
      "Val Loss: 0.5351\n",
      "Dice Score: 0.4608\n",
      "Saved best model with Dice score: 0.4608\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5453\n",
      "Val Loss: 0.5529\n",
      "Dice Score: 0.4690\n",
      "Saved best model with Dice score: 0.4690\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5273\n",
      "Val Loss: 0.4944\n",
      "Dice Score: 0.5445\n",
      "Saved best model with Dice score: 0.5445\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4837\n",
      "Val Loss: 0.4499\n",
      "Dice Score: 0.6237\n",
      "Saved best model with Dice score: 0.6237\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4665\n",
      "Val Loss: 0.4491\n",
      "Dice Score: 0.6141\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4306\n",
      "Val Loss: 0.3924\n",
      "Dice Score: 0.6611\n",
      "Saved best model with Dice score: 0.6611\n",
      "\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.30s/it, loss=0.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4126\n",
      "Val Loss: 0.4025\n",
      "Dice Score: 0.6455\n",
      "\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4060\n",
      "Val Loss: 0.3866\n",
      "Dice Score: 0.6543\n",
      "\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.30s/it, loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3895\n",
      "Val Loss: 0.3546\n",
      "Dice Score: 0.6808\n",
      "Saved best model with Dice score: 0.6808\n",
      "\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3599\n",
      "Val Loss: 0.3601\n",
      "Dice Score: 0.6836\n",
      "Saved best model with Dice score: 0.6836\n",
      "\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3548\n",
      "Val Loss: 0.3676\n",
      "Dice Score: 0.6717\n",
      "\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3617\n",
      "Val Loss: 0.3557\n",
      "Dice Score: 0.6811\n",
      "\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3419\n",
      "Val Loss: 0.3518\n",
      "Dice Score: 0.6839\n",
      "Saved best model with Dice score: 0.6839\n",
      "\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3444\n",
      "Val Loss: 0.3188\n",
      "Dice Score: 0.6962\n",
      "Saved best model with Dice score: 0.6962\n",
      "\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3386\n",
      "Val Loss: 0.2996\n",
      "Dice Score: 0.7290\n",
      "Saved best model with Dice score: 0.7290\n",
      "\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3223\n",
      "Val Loss: 0.3067\n",
      "Dice Score: 0.7103\n",
      "\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3288\n",
      "Val Loss: 0.3014\n",
      "Dice Score: 0.7224\n",
      "\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3310\n",
      "Val Loss: 0.2927\n",
      "Dice Score: 0.7298\n",
      "Saved best model with Dice score: 0.7298\n",
      "\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3127\n",
      "Val Loss: 0.2783\n",
      "Dice Score: 0.7456\n",
      "Saved best model with Dice score: 0.7456\n",
      "\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3135\n",
      "Val Loss: 0.2648\n",
      "Dice Score: 0.7525\n",
      "Saved best model with Dice score: 0.7525\n",
      "\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2986\n",
      "Val Loss: 0.3092\n",
      "Dice Score: 0.7148\n",
      "\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2884\n",
      "Val Loss: 0.3199\n",
      "Dice Score: 0.7091\n",
      "\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3115\n",
      "Val Loss: 0.2645\n",
      "Dice Score: 0.7530\n",
      "Saved best model with Dice score: 0.7530\n",
      "\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.30s/it, loss=0.309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3088\n",
      "Val Loss: 0.2828\n",
      "Dice Score: 0.7347\n",
      "\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2926\n",
      "Val Loss: 0.2632\n",
      "Dice Score: 0.7586\n",
      "Saved best model with Dice score: 0.7586\n",
      "\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2854\n",
      "Val Loss: 0.2753\n",
      "Dice Score: 0.7360\n",
      "\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2702\n",
      "Val Loss: 0.2731\n",
      "Dice Score: 0.7507\n",
      "\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2623\n",
      "Val Loss: 0.3117\n",
      "Dice Score: 0.7160\n",
      "\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2862\n",
      "Val Loss: 0.2616\n",
      "Dice Score: 0.7587\n",
      "Saved best model with Dice score: 0.7587\n",
      "\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2888\n",
      "Val Loss: 0.2450\n",
      "Dice Score: 0.7625\n",
      "Saved best model with Dice score: 0.7625\n",
      "\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.30s/it, loss=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2875\n",
      "Val Loss: 0.2802\n",
      "Dice Score: 0.7434\n",
      "\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2760\n",
      "Val Loss: 0.2451\n",
      "Dice Score: 0.7818\n",
      "Saved best model with Dice score: 0.7818\n",
      "\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.30s/it, loss=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2624\n",
      "Val Loss: 0.2511\n",
      "Dice Score: 0.7664\n",
      "\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2776\n",
      "Val Loss: 0.2570\n",
      "Dice Score: 0.7601\n",
      "\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2783\n",
      "Val Loss: 0.2565\n",
      "Dice Score: 0.7629\n",
      "\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2517\n",
      "Val Loss: 0.2289\n",
      "Dice Score: 0.7965\n",
      "Saved best model with Dice score: 0.7965\n",
      "\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2512\n",
      "Val Loss: 0.2390\n",
      "Dice Score: 0.7749\n",
      "\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2640\n",
      "Val Loss: 0.2553\n",
      "Dice Score: 0.7614\n",
      "\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2647\n",
      "Val Loss: 0.2468\n",
      "Dice Score: 0.7674\n",
      "\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2615\n",
      "Val Loss: 0.2486\n",
      "Dice Score: 0.7714\n",
      "\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it, loss=0.254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2539\n",
      "Val Loss: 0.2372\n",
      "Dice Score: 0.7704\n",
      "\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2392\n",
      "Val Loss: 0.2392\n",
      "Dice Score: 0.7668\n",
      "\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2604\n",
      "Val Loss: 0.2513\n",
      "Dice Score: 0.7623\n",
      "\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2586\n",
      "Val Loss: 0.2280\n",
      "Dice Score: 0.7942\n",
      "\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2335\n",
      "Val Loss: 0.2239\n",
      "Dice Score: 0.7946\n",
      "\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.29s/it, loss=0.239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2395\n",
      "Val Loss: 0.2207\n",
      "Dice Score: 0.7811\n",
      "Training completed!\n",
      "\n",
      "Evaluating final model on test set...\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [01:21<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "Average IoU: 0.6355 ± 0.2302\n",
      "Average Dice: 0.7468 ± 0.2185\n",
      "IoU Range: 0.0000 - 0.9291\n",
      "Dice Range: 0.0000 - 0.9633\n",
      "\n",
      "Creating confusion matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:23<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing completed!\n",
      "Results saved to /kaggle/working/results\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Set paths\n",
    "DATA_DIR = '/kaggle/input/kvasir-dataset/kvasir-instrument'\n",
    "RESULTS_DIR = '/kaggle/working/results'\n",
    "MOCO_CHECKPOINT = '/kaggle/input/moco/pytorch/default/1/final_moco_model.pth'\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class KvasirSegmentationDataset(Dataset):\n",
    "    def __init__(self, data_dir, split='train', transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all image files\n",
    "        image_dir = os.path.join(data_dir, 'images')\n",
    "        mask_dir = os.path.join(data_dir, 'masks')\n",
    "        \n",
    "        if not os.path.exists(image_dir):\n",
    "            raise RuntimeError(f'Image directory not found: {image_dir}')\n",
    "        if not os.path.exists(mask_dir):\n",
    "            raise RuntimeError(f'Mask directory not found: {mask_dir}')\n",
    "        \n",
    "        # Get all image files\n",
    "        self.images = sorted([\n",
    "            f for f in os.listdir(image_dir)\n",
    "            if f.endswith('.jpg')\n",
    "        ])\n",
    "        \n",
    "        # Verify corresponding masks exist\n",
    "        valid_pairs = []\n",
    "        for img_name in self.images:\n",
    "            mask_name = img_name.replace('.jpg', '.png')\n",
    "            mask_path = os.path.join(mask_dir, mask_name)\n",
    "            \n",
    "            if os.path.exists(mask_path):\n",
    "                valid_pairs.append((img_name, mask_name))\n",
    "        \n",
    "        if len(valid_pairs) == 0:\n",
    "            raise RuntimeError(f'No valid image-mask pairs found in {data_dir}')\n",
    "        \n",
    "        print(f\"Found {len(valid_pairs)} valid image-mask pairs\")\n",
    "        \n",
    "        # Split dataset\n",
    "        if split == 'train':\n",
    "            valid_pairs = valid_pairs[:int(0.8 * len(valid_pairs))]\n",
    "        elif split == 'val':\n",
    "            valid_pairs = valid_pairs[int(0.8 * len(valid_pairs)):]\n",
    "        \n",
    "        self.image_mask_pairs = valid_pairs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_mask_pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name, mask_name = self.image_mask_pairs[idx]\n",
    "        img_path = os.path.join(self.data_dir, 'images', img_name)\n",
    "        mask_path = os.path.join(self.data_dir, 'masks', mask_name)\n",
    "        \n",
    "        # Read image\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise RuntimeError(f'Failed to load image: {img_path}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Read mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            raise RuntimeError(f'Failed to load mask: {mask_path}')\n",
    "        \n",
    "        # Normalize mask to binary\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        # Add channel dimension to mask\n",
    "        mask = mask.unsqueeze(0)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "def get_training_augmentation():\n",
    "    return A.Compose([\n",
    "        A.RandomResizedCrop(512, 512, scale=(0.8, 1.0)),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n",
    "        A.OneOf([\n",
    "            A.ElasticTransform(alpha=120, sigma=120 * 0.05, p=0.5),\n",
    "            A.GridDistortion(p=0.5),\n",
    "            A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=0.5),\n",
    "        ], p=0.3),\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.HueSaturationValue(p=0.5),\n",
    "        ], p=0.3),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "class DeepLabV3PlusMoCo(nn.Module):\n",
    "    def __init__(self, moco_path):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load MoCo state dict\n",
    "        moco_state = torch.load(moco_path, weights_only=True)\n",
    "        \n",
    "        # Create DeepLabV3+ model\n",
    "        self.model = deeplabv3_resnet50(\n",
    "            weights=None,\n",
    "            num_classes=1,\n",
    "            aux_loss=None\n",
    "        )\n",
    "        \n",
    "        # Print a sample of the initial backbone weights\n",
    "        print(\"\\nInitial backbone weights (first layer):\")\n",
    "        for name, param in self.model.backbone.named_parameters():\n",
    "            if 'conv1.weight' in name:\n",
    "                print(f\"{name}: {param[0, 0, 0, 0].item()}\")\n",
    "                break\n",
    "        \n",
    "        # Get the state dict of MoCo's encoder_q\n",
    "        moco_dict = moco_state['model_state_dict']\n",
    "        encoder_dict = {k.replace('encoder_q.', ''): v for k, v in moco_dict.items() \n",
    "                       if k.startswith('encoder_q.') and not k.startswith('encoder_q.fc')}\n",
    "        \n",
    "        # Load MoCo weights into backbone\n",
    "        missing_keys, unexpected_keys = self.model.backbone.load_state_dict(encoder_dict, strict=False)\n",
    "        print(f\"Missing keys: {missing_keys}\")\n",
    "        print(f\"Unexpected keys: {unexpected_keys}\")\n",
    "        \n",
    "        # Print a sample of the loaded MoCo weights\n",
    "        print(\"\\nLoaded MoCo weights (first layer):\")\n",
    "        for name, param in self.model.backbone.named_parameters():\n",
    "            if 'conv1.weight' in name:\n",
    "                print(f\"{name}: {param[0, 0, 0, 0].item()}\")\n",
    "                break\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "def dice_loss(pred, target):\n",
    "    smooth = 1.0\n",
    "    # Handle model output dictionary\n",
    "    if isinstance(pred, dict):\n",
    "        pred = pred['out']\n",
    "    pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * target).sum(dim=(2,3))\n",
    "    union = pred.sum(dim=(2,3)) + target.sum(dim=(2,3))\n",
    "    \n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with tqdm(loader) as pbar:\n",
    "        for images, masks in pbar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': total_loss / (pbar.n + 1)})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def visualize_predictions(model, dataset, device, num_samples=4, save_dir=None, epoch=None):\n",
    "    \"\"\"Visualize predictions for a few samples\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a figure\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    # Get random samples\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, sample_idx in enumerate(indices):\n",
    "            # Get sample\n",
    "            image, mask = dataset[sample_idx]\n",
    "            \n",
    "            # Add batch dimension\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "            \n",
    "            # Get prediction\n",
    "            output = model(image)\n",
    "            pred = torch.sigmoid(output['out']).cpu()\n",
    "            pred_mask = (pred > 0.5).float()\n",
    "            \n",
    "            # Convert tensors to numpy arrays\n",
    "            image = image.cpu().squeeze().permute(1,2,0).numpy()\n",
    "            image = (image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])) * 255\n",
    "            image = image.astype(np.uint8)\n",
    "            \n",
    "            mask = mask.squeeze().numpy()\n",
    "            pred_mask = pred_mask.squeeze().numpy()\n",
    "            \n",
    "            # Plot\n",
    "            axes[idx, 0].imshow(image)\n",
    "            axes[idx, 0].set_title('Input Image')\n",
    "            axes[idx, 0].axis('off')\n",
    "            \n",
    "            axes[idx, 1].imshow(mask, cmap='gray')\n",
    "            axes[idx, 1].set_title('Ground Truth')\n",
    "            axes[idx, 1].axis('off')\n",
    "            \n",
    "            axes[idx, 2].imshow(pred_mask, cmap='gray')\n",
    "            axes[idx, 2].set_title('Prediction')\n",
    "            axes[idx, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_dir:\n",
    "        epoch_str = f'_epoch_{epoch}' if epoch is not None else ''\n",
    "        plt.savefig(os.path.join(save_dir, f'predictions{epoch_str}.png'))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def validate(model, loader, criterion, device, writer=None, epoch=None, save_dir=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    dice_scores = []\n",
    "    \n",
    "    # Store some examples for visualization\n",
    "    vis_images = []\n",
    "    vis_masks = []\n",
    "    vis_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Calculate Dice score\n",
    "            pred = torch.sigmoid(outputs['out'])\n",
    "            pred = (pred > 0.5).float()\n",
    "            dice = (2.0 * (pred * masks).sum()) / (pred.sum() + masks.sum() + 1e-8)\n",
    "            dice_scores.append(dice.item())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Store first batch for visualization\n",
    "            if i == 0:\n",
    "                vis_images.extend([img for img in images[:4]])\n",
    "                vis_masks.extend([mask for mask in masks[:4]])\n",
    "                vis_preds.extend([p for p in pred[:4]])\n",
    "    \n",
    "    # Log images to tensorboard\n",
    "    if writer is not None and epoch is not None:\n",
    "        # Create visualization grid\n",
    "        vis_images = torch.stack(vis_images)\n",
    "        vis_masks = torch.stack(vis_masks)\n",
    "        vis_preds = torch.stack(vis_preds)\n",
    "        \n",
    "        # Denormalize images\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(device)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(device)\n",
    "        vis_images = vis_images * std + mean\n",
    "        \n",
    "        # Create grids\n",
    "        image_grid = make_grid(vis_images, nrow=4, normalize=True)\n",
    "        mask_grid = make_grid(vis_masks, nrow=4)\n",
    "        pred_grid = make_grid(vis_preds, nrow=4)\n",
    "        \n",
    "        # Log to tensorboard\n",
    "        writer.add_image('Images/Input', image_grid, epoch)\n",
    "        writer.add_image('Images/GroundTruth', mask_grid, epoch)\n",
    "        writer.add_image('Images/Prediction', pred_grid, epoch)\n",
    "    \n",
    "    # Save detailed visualizations\n",
    "    if save_dir is not None:\n",
    "        os.makedirs(os.path.join(save_dir, 'visualizations'), exist_ok=True)\n",
    "        visualize_predictions(\n",
    "            model, \n",
    "            loader.dataset, \n",
    "            device, \n",
    "            num_samples=4,\n",
    "            save_dir=os.path.join(save_dir, 'visualizations'),\n",
    "            epoch=epoch\n",
    "        )\n",
    "    \n",
    "    return total_loss / len(loader), np.mean(dice_scores)\n",
    "\n",
    "def calculate_metrics(pred_mask, gt_mask):\n",
    "    \"\"\"Calculate IoU and Dice score for binary segmentation\"\"\"\n",
    "    # Convert to binary masks\n",
    "    pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
    "    gt_mask = (gt_mask > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Calculate intersection and union\n",
    "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
    "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = intersection / (union + 1e-8)\n",
    "    \n",
    "    # Calculate Dice score\n",
    "    dice = (2 * intersection) / (pred_mask.sum() + gt_mask.sum() + 1e-8)\n",
    "    \n",
    "    return iou, dice\n",
    "\n",
    "def test_model(model, test_loader, device, save_dir=None):\n",
    "    \"\"\"Evaluate model on test set and calculate metrics\"\"\"\n",
    "    model.eval()\n",
    "    total_iou = 0\n",
    "    total_dice = 0\n",
    "    all_ious = []\n",
    "    all_dices = []\n",
    "    \n",
    "    # Create directory for saving test results\n",
    "    if save_dir:\n",
    "        os.makedirs(os.path.join(save_dir, 'test_results'), exist_ok=True)\n",
    "    \n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(tqdm(test_loader)):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs['out'])\n",
    "            pred_masks = (preds > 0.5).float()\n",
    "            \n",
    "            # Calculate metrics for each image in batch\n",
    "            for j in range(len(images)):\n",
    "                pred_mask = pred_masks[j, 0].cpu().numpy()\n",
    "                gt_mask = masks[j, 0].cpu().numpy()\n",
    "                \n",
    "                iou, dice = calculate_metrics(pred_mask, gt_mask)\n",
    "                total_iou += iou\n",
    "                total_dice += dice\n",
    "                all_ious.append(iou)\n",
    "                all_dices.append(dice)\n",
    "                \n",
    "                # Save visualization if requested\n",
    "                if save_dir:\n",
    "                    plt.figure(figsize=(15, 5))\n",
    "                    \n",
    "                    # Original image\n",
    "                    plt.subplot(131)\n",
    "                    img = images[j].cpu().numpy().transpose(1, 2, 0)\n",
    "                    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                    img = np.clip(img, 0, 1)\n",
    "                    plt.imshow(img)\n",
    "                    plt.title('Original Image')\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    # Ground truth\n",
    "                    plt.subplot(132)\n",
    "                    plt.imshow(gt_mask, cmap='gray')\n",
    "                    plt.title('Ground Truth')\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    # Prediction\n",
    "                    plt.subplot(133)\n",
    "                    plt.imshow(pred_mask, cmap='gray')\n",
    "                    plt.title(f'Prediction (IoU: {iou:.3f}, Dice: {dice:.3f})')\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.suptitle(f'Test Sample {i*len(images) + j}')\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(save_dir, 'test_results', f'test_sample_{i*len(images) + j}.png'))\n",
    "                    plt.close()\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_iou = total_iou / len(test_loader.dataset)\n",
    "    avg_dice = total_dice / len(test_loader.dataset)\n",
    "    \n",
    "    # Calculate standard deviation\n",
    "    std_iou = np.std(all_ious)\n",
    "    std_dice = np.std(all_dices)\n",
    "    \n",
    "    # Calculate min and max metrics\n",
    "    min_iou = min(all_ious)\n",
    "    max_iou = max(all_ious)\n",
    "    min_dice = min(all_dices)\n",
    "    max_dice = max(all_dices)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"Average IoU: {avg_iou:.4f} ± {std_iou:.4f}\")\n",
    "    print(f\"Average Dice: {avg_dice:.4f} ± {std_dice:.4f}\")\n",
    "    print(f\"IoU Range: {min_iou:.4f} - {max_iou:.4f}\")\n",
    "    print(f\"Dice Range: {min_dice:.4f} - {max_dice:.4f}\")\n",
    "    \n",
    "    # Save metrics to file\n",
    "    if save_dir:\n",
    "        with open(os.path.join(save_dir, 'test_metrics.txt'), 'w') as f:\n",
    "            f.write(f\"Test Results:\\n\")\n",
    "            f.write(f\"Average IoU: {avg_iou:.4f} ± {std_iou:.4f}\\n\")\n",
    "            f.write(f\"Average Dice: {avg_dice:.4f} ± {std_dice:.4f}\\n\")\n",
    "            f.write(f\"IoU Range: {min_iou:.4f} - {max_iou:.4f}\\n\")\n",
    "            f.write(f\"Dice Range: {min_dice:.4f} - {max_dice:.4f}\\n\")\n",
    "            f.write(f\"Number of test samples: {len(test_loader.dataset)}\\n\")\n",
    "    \n",
    "    # Create a summary visualization of all test results\n",
    "    if save_dir:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(all_ious, bins=20, alpha=0.7, label='IoU')\n",
    "        plt.hist(all_dices, bins=20, alpha=0.7, label='Dice')\n",
    "        plt.axvline(avg_iou, color='blue', linestyle='dashed', linewidth=1, label=f'Avg IoU: {avg_iou:.3f}')\n",
    "        plt.axvline(avg_dice, color='orange', linestyle='dashed', linewidth=1, label=f'Avg Dice: {avg_dice:.3f}')\n",
    "        plt.xlabel('Score')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distribution of IoU and Dice Scores on Test Set')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(os.path.join(save_dir, 'test_results', 'score_distribution.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    return avg_iou, avg_dice, all_ious, all_dices\n",
    "\n",
    "def create_confusion_matrix(model, test_loader, device, save_dir=None):\n",
    "    \"\"\"Create confusion matrix visualization for the test set\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    print(\"\\nCreating confusion matrix...\")\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs['out'])\n",
    "            pred_masks = (preds > 0.5).float()\n",
    "            \n",
    "            # Flatten predictions and targets\n",
    "            pred_masks = pred_masks.cpu().numpy().flatten()\n",
    "            masks = masks.cpu().numpy().flatten()\n",
    "            \n",
    "            all_preds.extend(pred_masks)\n",
    "            all_targets.extend(masks)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Background', 'Polyp'],\n",
    "                yticklabels=['Background', 'Polyp'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Ground Truth')\n",
    "    plt.title('Confusion Matrix')\n",
    "    \n",
    "    # Add metrics text\n",
    "    plt.text(0.5, -0.3, f'Accuracy: {accuracy:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\\nF1: {f1:.4f}',\n",
    "             horizontalalignment='center', transform=plt.gca().transAxes)\n",
    "    \n",
    "    if save_dir:\n",
    "        plt.savefig(os.path.join(save_dir, 'test_results', 'confusion_matrix.png'), bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Save metrics to file\n",
    "        with open(os.path.join(save_dir, 'test_metrics.txt'), 'a') as f:\n",
    "            f.write(f\"\\nConfusion Matrix Metrics:\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "            f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "            f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "            f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return cm, accuracy, precision, recall, f1\n",
    "\n",
    "def main():\n",
    "    # Set random seed\n",
    "    set_seed(42)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    full_dataset = KvasirSegmentationDataset(DATA_DIR, transform=get_training_augmentation())\n",
    "    \n",
    "    # Split into train (50%), val (20%), and test (30%)\n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(0.5 * total_size)\n",
    "    val_size = int(0.2 * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "    \n",
    "    indices = list(range(total_size))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "    \n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    val_dataset = Subset(full_dataset, val_indices)\n",
    "    test_dataset = Subset(full_dataset, test_indices)\n",
    "    \n",
    "    print(f\"Dataset split: {len(train_dataset)} train, {len(val_dataset)} val, {len(test_dataset)} test\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Create model\n",
    "    model = DeepLabV3PlusMoCo(MOCO_CHECKPOINT).to(device)\n",
    "    \n",
    "    # Create optimizer and scheduler\n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': model.model.backbone.parameters(), 'lr': 1e-5},\n",
    "        {'params': model.model.classifier.parameters(), 'lr': 1e-4},\n",
    "    ])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5\n",
    "    )\n",
    "    \n",
    "    # Create criterion\n",
    "    criterion = dice_loss\n",
    "    \n",
    "    # Initialize tensorboard\n",
    "    writer = SummaryWriter(os.path.join(RESULTS_DIR, 'deeplabv3plus_semisup_logs'))\n",
    "    \n",
    "    # Create results and visualization directories\n",
    "    os.makedirs(os.path.join(RESULTS_DIR, 'visualizations'), exist_ok=True)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 50\n",
    "    best_dice = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validate with visualizations\n",
    "        val_loss, dice_score = validate(\n",
    "            model, \n",
    "            val_loader, \n",
    "            criterion, \n",
    "            device,\n",
    "            writer=writer,\n",
    "            epoch=epoch,\n",
    "            save_dir=RESULTS_DIR\n",
    "        )\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Log metrics\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        writer.add_scalar('Dice/val', dice_score, epoch)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Dice Score: {dice_score:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if dice_score > best_dice:\n",
    "            best_dice = dice_score\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_dice': best_dice,\n",
    "            }, os.path.join(RESULTS_DIR, 'best_deeplabv3plus_semisup_model.pth'))\n",
    "            print(f\"Saved best model with Dice score: {best_dice:.4f}\")\n",
    "        \n",
    "        # Save checkpoint every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_dice': best_dice,\n",
    "            }, os.path.join(RESULTS_DIR, f'deeplabv3plus_semisup_checkpoint_epoch_{epoch+1}.pth'))\n",
    "    \n",
    "    writer.close()\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "    # After training, evaluate on test set\n",
    "    print(\"\\nEvaluating final model on test set...\")\n",
    "    test_iou, test_dice, all_ious, all_dices = test_model(\n",
    "        model, \n",
    "        test_loader, \n",
    "        device,\n",
    "        save_dir=RESULTS_DIR\n",
    "    )\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    create_confusion_matrix(model, test_loader, device, save_dir=RESULTS_DIR)\n",
    "    \n",
    "    # Save final test metrics with methodology summary\n",
    "    with open(os.path.join(RESULTS_DIR, 'final_test_metrics.txt'), 'w') as f:\n",
    "        f.write(f\"Methodology Summary:\\n\")\n",
    "        f.write(f\"1. Self-supervised pretraining with MoCo on unlabeled data\\n\")\n",
    "        f.write(f\"2. Fine-tuning DeepLabV3+ with MoCo pretrained features on 50% labeled data\\n\")\n",
    "        f.write(f\"3. Validation on 20% of data\\n\")\n",
    "        f.write(f\"4. Testing on 30% of data\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Final Test Results:\\n\")\n",
    "        f.write(f\"Average IoU: {test_iou:.4f}\\n\")\n",
    "        f.write(f\"Average Dice: {test_dice:.4f}\\n\")\n",
    "        f.write(f\"Number of test samples: {len(test_dataset)}\\n\")\n",
    "        \n",
    "        # Add training history summary\n",
    "        f.write(f\"\\nTraining History:\\n\")\n",
    "        f.write(f\"Best validation Dice score: {best_dice:.4f}\\n\")\n",
    "        f.write(f\"Final training loss: {train_loss:.4f}\\n\")\n",
    "        f.write(f\"Final validation loss: {val_loss:.4f}\\n\")\n",
    "    \n",
    "    print(\"Testing completed!\")\n",
    "    print(f\"Results saved to {RESULTS_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d887d74",
   "metadata": {
    "papermill": {
     "duration": 0.140424,
     "end_time": "2025-04-17T20:55:49.341302",
     "exception": false,
     "start_time": "2025-04-17T20:55:49.200878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51014a43",
   "metadata": {
    "papermill": {
     "duration": 0.143794,
     "end_time": "2025-04-17T20:55:49.628446",
     "exception": false,
     "start_time": "2025-04-17T20:55:49.484652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6712118,
     "sourceId": 10812212,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 293993,
     "modelInstanceId": 273030,
     "sourceId": 324135,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7374.716001,
   "end_time": "2025-04-17T20:55:52.898093",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-17T18:52:58.182092",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
